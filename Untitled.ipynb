{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Write-Up\n",
    "\n",
    "## Explaining Custom Layers\n",
    "\n",
    "The process behind converting custom layers involves...\n",
    "\n",
    "Some of the potential reasons for handling custom layers are...\n",
    "\n",
    "## Comparing Model Performance\n",
    "\n",
    "My method(s) to compare models before and after conversion to Intermediate Representations\n",
    "were...\n",
    "\n",
    "<table style=\"width:100%\" border=\"2\">\n",
    "  <tr>\n",
    "    <th rowspan=\"2\">Model</th>\n",
    "    <th colspan=\"3\">Pre-conversion size</th>\n",
    "    <th colspan=\"3\">Post-conversion size</th> \n",
    "  </tr>\n",
    "  <tr>\n",
    "  \t<th>Size</th>\n",
    "  \t<th>Accuracy</th>\n",
    "  \t<th>Inference time</th>\n",
    "  \t<th>Size</th>\n",
    "  \t<th>Accuracy</th>\n",
    "  \t<th>Inference time</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "  \t<td>faster_rcnn_resnet50</td>\n",
    "    <td></td>\n",
    "    <td></td>\n",
    "    <td></td>\n",
    "    <td></td>\n",
    "    <td>95.40%</td>\n",
    "    <td>01:17:38</td>\n",
    "  </tr>\n",
    "   <tr>\n",
    "  \t<td>faster_rcnn_resnet101</td>\n",
    "    <td>187 MB</td>\n",
    "    <td></td>\n",
    "    <td></td>\n",
    "    <td></td>\n",
    "    <td></td>\n",
    "    <td></td>\n",
    "  </tr>\n",
    "   <tr>\n",
    "  \t<td>faster_rcnn_inception_v2</td>\n",
    "    <td></td>\n",
    "    <td></td>\n",
    "    <td></td>\n",
    "    <td></td>\n",
    "    <td></td>\n",
    "    <td></td>\n",
    "  </tr>\n",
    "   <tr>\n",
    "  \t<td>faster_rcnn_inception_resnet_v2_atrous</td>\n",
    "    <td></td>\n",
    "    <td></td>\n",
    "    <td></td>\n",
    "    <td></td>\n",
    "    <td></td>\n",
    "    <td></td>\n",
    "  </tr>\n",
    "   <tr>\n",
    "  \t<td>rfcn_resnet101</td>\n",
    "    <td></td>\n",
    "    <td></td>\n",
    "    <td></td>\n",
    "    <td></td>\n",
    "    <td></td>\n",
    "    <td></td>\n",
    "  </tr>\n",
    "   <tr>\n",
    "  \t<td>ssdlite_mobilenet_v2</td>\n",
    "    <td></td>\n",
    "    <td></td>\n",
    "    <td></td>\n",
    "    <td></td>\n",
    "    <td>79.05%</td>\n",
    "    <td>02:36</td>\n",
    "  </tr>\n",
    "   <tr>\n",
    "  \t<td>person-detection-retail-0013</td>\n",
    "    <td></td>\n",
    "    <td></td>\n",
    "    <td></td>\n",
    "    <td></td>\n",
    "    <td>97.99%</td>\n",
    "    <td>02:58</td>\n",
    "  </tr>\n",
    "\n",
    "</table>\n",
    "\n",
    "Accuracy = (No. of frames a person is detected with bounding box)/(no. of frames person was present)\n",
    "\n",
    "inference time(time it takes per frame to predict/get those detections in milliseconds)\n",
    "accuracy(in count as it will keep on fluctuating as bounding boxes will drop)\n",
    "size of model (pretrained tf vs ir converted)\n",
    "\n",
    "For size, compare the file size of .pb (Tensorflow) and .bin (IR).\n",
    "Accuracy: Overall, how often is the classifier correct?\n",
    "(TP+TN)/total = (100+50)/165 = 0.91\n",
    "\n",
    "\n",
    "## Assess Model Use Cases\n",
    "\n",
    "Some of the potential use cases of the people counter app are:\n",
    "- **it can be used in any place where people should not get exposed to radiation for a long time**\n",
    "\n",
    "Each of these use cases would be useful because...\n",
    "- **it will calculate the time each person spends in the room, if they spend time more than the allowed they get a warning**\n",
    "\n",
    "## Assess Effects on End User Needs\n",
    "\n",
    "Lighting, model accuracy, and camera focal length/image size have different effects on a\n",
    "deployed edge model. The potential effects of each of these are as follows...\n",
    "\n",
    "## Model Research\n",
    "\n",
    "[This heading is only required if a suitable model was not found after trying out at least three\n",
    "different models. However, you may also use this heading to detail how you converted \n",
    "a successful model.]\n",
    "\n",
    "Download the model\n",
    "```\n",
    "wget model_link\n",
    "```\n",
    "Unzipp the model\n",
    "```\n",
    "tar -xvf model_name.tar.gz\n",
    "```\n",
    "cd to the model folder\n",
    "```\n",
    "cd model_name\n",
    "```\n",
    "\n",
    "In investigating potential people counter models, I tried each of the following models:\n",
    "- [faster_rcnn_resnet50](http://download.tensorflow.org/models/object_detection/faster_rcnn_resnet50_coco_2018_01_28.tar.gz)\n",
    "- [faster_rcnn_resnet101](http://download.tensorflow.org/models/object_detection/faster_rcnn_resnet101_coco_2018_01_28.tar.gz)\n",
    "- [faster_rcnn_inception_v2](http://download.tensorflow.org/models/object_detection/faster_rcnn_inception_v2_coco_2018_01_28.tar.gz)\n",
    "- [faster_rcnn_inception_resnet_v2_atrous](http://download.tensorflow.org/models/object_detection/faster_rcnn_inception_resnet_v2_atrous_coco_2018_01_28.tar.gz)\n",
    "    - I converted the above models to an Intermediate Representation with the following arguments:\n",
    "  \n",
    "  \n",
    "```\n",
    "python /opt/intel/openvino/deployment_tools/model_optimizer/mo.py  \\\n",
    "--input_model frozen_inference_graph.pb \\\n",
    "--reverse_input_channels \\\n",
    "--data_type FP16 \\\n",
    "--tensorflow_object_detection_api_pipeline_config pipeline.config \\\n",
    "--tensorflow_use_custom_operations_config /opt/intel/openvino/deployment_tools/model_optimizer/extensions/front/tf/faster_rcnn_support.json\n",
    "\n",
    "```\n",
    "\n",
    "- [rfcn_resnet101](http://download.tensorflow.org/models/object_detection/rfcn_resnet101_coco_2018_01_28.tar.gz)\n",
    "   - I converted the model to an Intermediate Representation with the following arguments...\n",
    "   \n",
    "```\n",
    "python /opt/intel/openvino/deployment_tools/model_optimizer/mo.py  \\\n",
    "--input_model frozen_inference_graph.pb \\\n",
    "--reverse_input_channels \\\n",
    "--data_type FP16 \\\n",
    "--tensorflow_object_detection_api_pipeline_config pipeline.config \\\n",
    "--tensorflow_use_custom_operations_config /opt/intel/openvino/deployment_tools/model_optimizer/extensions/front/tf/rfcn_support.json\n",
    "\n",
    "```\n",
    "  - The above models was insufficient for the app because **they were so slow and took too much time to complete inference on the video.**\n",
    "  - I tried to improve the models for the app by **using one of the optimization techniques \"quantization\" and that by reducing precision to FP16**.\n",
    " \n",
    "- [ssdlite_mobilenet_v2](http://download.tensorflow.org/models/object_detection/ssdlite_mobilenet_v2_coco_2018_05_09.tar.gz)\n",
    "  - I converted the model to an Intermediate Representation with the following arguments:\n",
    "```\n",
    "python /opt/intel/openvino/deployment_tools/model_optimizer/mo.py  \\\n",
    "--input_model frozen_inference_graph.pb \\\n",
    "--reverse_input_channels \\\n",
    "--tensorflow_object_detection_api_pipeline_config pipeline.config \\\n",
    "--tensorflow_use_custom_operations_config /opt/intel/openvino/deployment_tools/model_optimizer/extensions/front/tf/ssd_v2_support.json\n",
    "```\n",
    "\n",
    "  - The model was insufficient for the app because **it wasn't accurate, the model didn't detect the second person in the video for more than 10 frames.**\n",
    "  - I tried to improve the model for the app by **giving the confidence threshold lower values.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6220355269907727\n"
     ]
    }
   ],
   "source": [
    "total_count = 1000000\n",
    "threshold = 1e-4 \n",
    "\n",
    "# Calculate frequency of words\n",
    "word_freq = 700/total_count\n",
    "import numpy as np\n",
    "# Calculate discard probability of words\n",
    "word_prob = 1 - np.sqrt(threshold/word_freq)\n",
    "print(word_prob)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
